{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria lingwistyczna\n",
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1 - tokenizacja (12 pkt)\n",
    "\n",
    "Jedną z nowoczesnych technik tokenizacji jest BPE - byte-pair encoding [1]. Technika ta polega na podzielenie słów na częste podsłowa (morfemy). W przeciwieństwie do podejść lingwistycznych, wymagających reguł tworzenia morfemów, BPE wyznacza je automatycznie poprzez wyznaczenie najczęstszych przylegających do siebie sekwencji znaków które występują obok siebie.\n",
    "\n",
    "Algorytm przebiega w następujących krokach.\n",
    "1. Podziel wszystkie słowa na symbole (początkowo pojedyncze znaki)\n",
    "2. Wyznacz najczęściej występującą obok siebie parę symboli \n",
    "3. Stwórz nowy symbol będący konkatenacją dwóch najczęstszych symboli.\n",
    "\n",
    "Uwaga 1: każde słowo zakończone jest specjalnym symbolem końca wyrazu.\n",
    "\n",
    "Uwaga 2: tworzenie nowego symbolu nie powoduje usuniecie starego tj. zawsze jednym z możliwych symboli jest pojedynczy znak, ale jeśli można to stosujemy symbol dłuższy.\n",
    "\n",
    "Przykład: korpus w którym występuje ,,ala'' 5 razy i ,,mama 10 razy''\n",
    "1. Dzielimy słowa na symbole ,,a l a END'' ,,m a m a END''  gdzie END jest symbolem końca wyrazu.\n",
    "2. Najczęstsza para obok siebie to ,,m a'' (20) razy\n",
    "3. Nowy symbol ,,ma''\n",
    "4. Nowy podział ,,a l a END'' ,,ma ma END''\n",
    "5. Najczęstsza para ,,ma ma'' (10) razy\n",
    "6. Nowy symbol ,,mama''\n",
    "7. Nowy podział ,,a l a END'' ,,mama END''\n",
    "8. itd.\n",
    "\n",
    "W pliku ,,brown_clusters.tsv'' pierwsza kolumna to identyfikator skupienia (nie używamy w tym zadaniu), druga kolumna to wyrazy, a trzecia to ich liczności w pewnym korpusie tweetów. Zaimplementuj technike BPE na tych słowach.\n",
    "\n",
    "Zaimplementuj algorytm BPE wykonujący `number_of_iterations` iteracji (łączeń symboli).\n",
    "\n",
    "[1] Sennrich, R., Haddow, B., and Birch, A. (2016). Neural machine translation of rare words with subword units. In ACL 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ff3b90528fdb50de90c5c946c157e21",
     "grade": false,
     "grade_id": "cell-93d78a28d4e25cbc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "brown_df = pd.read_csv('brown_clusters.tsv', sep='\\t', header=0, names=['cluster', 'word', 'count'])\n",
    "\n",
    "number_of_iterations = 10\n",
    "END = 'END'\n",
    "def preform_bpe(brown_df, number_of_iterations, verbose=False):\n",
    "    \"\"\"\n",
    "    Funckcja przyjmuje ramkę w formacie analogicznym do obiektu brown_df (wczytany wyżej)\n",
    "     oraz liczbę iteracji.\n",
    "    Wyjściem funkcji powinna być lista słów z poszczególnymi tokenami/symbolami oddzielonymi spacją.\n",
    "    Za znak końca wyrazu przyjmij END. \n",
    "    \"\"\"\n",
    "    l = df_to_symbols(brown_df)\n",
    "    for _ in range(number_of_iterations):\n",
    "        pair = most_frequent_pair(l)\n",
    "        if not pair:\n",
    "            break\n",
    "        if verbose:\n",
    "            print(pair)\n",
    "        l = update_symbols(l, pair)\n",
    "    \n",
    "    return [' '.join(w) for w, c in l]\n",
    "    \n",
    "\n",
    "def df_to_symbols(brown_df):\n",
    "    return [\n",
    "        (list(word) + [END], count)\n",
    "        for i, (_, word, count)\n",
    "        in brown_df.head(10).iterrows()\n",
    "    ]\n",
    "\n",
    "def most_frequent_pair(words):\n",
    "    counter = Counter()\n",
    "    for word, count in words:\n",
    "        for i, sym in enumerate(word[:-2]):\n",
    "            pair = (sym, word[i+1])\n",
    "            counter.update({pair: count})\n",
    "    candidates = counter.most_common(1)\n",
    "    if candidates:\n",
    "        return candidates[0][0]\n",
    "\n",
    "def update_symbols(words, pair):\n",
    "    return [\n",
    "        (replace_symbol(word, pair), count)\n",
    "        for word, count\n",
    "        in words\n",
    "    ]\n",
    "\n",
    "def replace_symbol(word, pair):\n",
    "    a, b = pair\n",
    "    while a in word and b in word:\n",
    "        ai = word.index(a)\n",
    "        bi = word.index(b)\n",
    "        if ai + 1 == bi:\n",
    "            word[ai:bi+1] = [''.join(pair)]\n",
    "        else:\n",
    "            break\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test implementacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfff70f711bf389f0f1cd969e7c3a413",
     "grade": true,
     "grade_id": "cell-7e952fa8dcd136fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_list_equal\n",
    "data = {'cluster': range(2), 'word':['ala', 'mama'], 'count': [5,10]}\n",
    "df = pd.DataFrame (data, columns = ['cluster', 'word', 'count'])\n",
    "vocab = preform_bpe(df, 1)\n",
    "assert_list_equal(vocab, ['a l a END', 'ma ma END'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spraw aby Twoja implementacja wypisywała kolejne łączone ze sobą symbole i uruchom Twoją funkcję na np. 50 iteracji, obserwując jakie tokeny są tworzone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e', 'v')\n",
      "('i', 'n')\n",
      "('-', 'i')\n",
      "('»', 'i')\n",
      "('-i', '-')\n",
      "('in', 'ev')\n",
      "('inev', 'a')\n",
      "('#', 'y')\n",
      "('#y', 'o')\n",
      "('#yo', 'u')\n",
      "('#you', 'ev')\n",
      "('#youev', 'e')\n",
      "('#youeve', 'r')\n",
      "('i', 'f')\n",
      "('if', 'i')\n",
      "('ifi', 'n')\n",
      "('ifin', 'a')\n",
      "('ifina', 'l')\n",
      "('ifinal', 'l')\n",
      "('ifinall', 'y')\n",
      "('「', 'i')\n",
      "('t', 'o')\n",
      "('to', 'd')\n",
      "('tod', 'a')\n",
      "('toda', 'y')\n",
      "('today', '-i')\n",
      "('n', 'o')\n",
      "('no', 'w')\n",
      "('now', 'i')\n",
      "('\\\\', 'i')\n",
      "('/', 'i')\n",
      "('/i', '/')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\\\i END',\n",
       " '/i/ END',\n",
       " 'today-i END',\n",
       " 'nowi END',\n",
       " '#youever END',\n",
       " 'ifinally END',\n",
       " '「i END',\n",
       " '-i- END',\n",
       " 'ineva END',\n",
       " '»i END']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preform_bpe(brown_df, 50, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9888b25499797c4fb0fd4f13646b0c3c",
     "grade": false,
     "grade_id": "cell-7d1e49878db56df4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie angielskie słowo jako pierwsze dostało swój własny token?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df4c7b8b5aa2b077eaa2d42429797139",
     "grade": true,
     "grade_id": "cell-acd48c77e2c1bcec",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "`in`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd51e6fc0cd1d3b4d8b9e9a2fa1b0316",
     "grade": false,
     "grade_id": "cell-df60f5e5c6fe4ca0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie są zalety korzystania z tokenizacji BPE w kontekście tworzenia reprezentacji (problem OOV, odnieś się do  k-gramów i n-gramów)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64306e36b58f1eee12c8bb339123e105",
     "grade": true,
     "grade_id": "cell-006ef6fd3e397206",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2 - klasyfikacja (15 pkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy kod powinien wczytać i ztokenizować zbiór danych dot. analizy wydźwięku. Jeśli nie masz biblioteki `nltk` musisz ją zainstalować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data set ['tweets.txt']\n"
     ]
    }
   ],
   "source": [
    "from helpers import DataSet\n",
    "training_set = DataSet(['tweets.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajdziesz przykład odczytu jednego tweeta z obiektu DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.\n",
      "['dear', '@microsoft', 'the', 'newooffice', 'for', 'mac', 'is', 'great', 'and', 'all', ',', 'but', 'no', 'lync', 'update', '?', \"c'mon\", '.']\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for i in training_set.tweets:\n",
    "    print(i.text)\n",
    "    print(i.tokens)\n",
    "    print(i.clazz)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systemy IL często pracują z bardzo dużą liczbą cech, które są rzadkie np. cechy Bag-Of-Words, cechy n-gramowe itd. Powoduje to że klasyczna macierz przykłady uczące na cechy rośnie do bardzo dużych rozmiarów nawet dla małych zbiorów uczących (w sensie liczby przykładów). Ponadto samo przechowywanie w pamięci słownika mapującego konkretne słowa/n-gramy na indeksy kolumn macierzy może być bardzo kosztowne pamięciowo przy dużych rozmiarach słownika.\n",
    "\n",
    "Istnieje jednak technika, która pozwala nam na ominięcie tej przeszkody: haszowanie cech. Opis tej techniki znajdziesz na stronie:  https://en.wikipedia.org/wiki/Feature_hashing Jest ona też implementowana w obiekcie `sklearn.feature_extraction.FeatureHasher`. Zapoznaj się z opisem techniki i wykonaj poniższe polecenia.\n",
    "\n",
    "- Wykorzystując haszowanie cech wytrenuj wybrany klasyfikator na zbiorze uczącym dla cech Bag-of-words (możesz też spróbować cechy n-gramowe). Możesz wykorzystać gotową tokenizację we właściwości `.tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac05ad71ee90b1c800030849c5321cb7",
     "grade": true,
     "grade_id": "cell-f6cfe39258fbec51",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def bag_of_words(tweets):\n",
    "    return [Counter(tweet.tokens) for tweet in tweets]\n",
    "\n",
    "def tweet_classes(tweets):\n",
    "    return [tweet.clazz for tweet in tweets]\n",
    "\n",
    "def train_hashing_svm(tweets, n_features=32):\n",
    "    pipeline = Pipeline([\n",
    "        ('hasher', FeatureHasher(n_features)),\n",
    "        ('svm', SVC())\n",
    "    ])\n",
    "    pipeline.fit(bag_of_words(tweets), tweet_classes(tweets))\n",
    "    return pipeline\n",
    "\n",
    "# train_hashing_svm(training_set.tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6bcaf8dae7184b60bd9a8adadd85d8",
     "grade": false,
     "grade_id": "cell-1caf16c401c91ef2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Stwórz wykres zależności wybranej miary klasyfikacji od wymiarów macierzy danych (chodzi o liczbę cech do których haszujemy cechy oryginalne). Wystarczy przetestować kilka (>=4) wybranych wartości na skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bd253bac561b269cff3a3dceadc70f0",
     "grade": true,
     "grade_id": "cell-8076c16242981ae9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "size = len(training_set.tweets)\n",
    "train_size = int(size * 0.75)\n",
    "train = training_set.tweets[0:train_size]\n",
    "test = training_set.tweets[train_size+1:]\n",
    "\n",
    "test_bow = bag_of_words(test)\n",
    "test_classes = tweet_classes(test)\n",
    "\n",
    "dims = 2**np.arange(4, 12)\n",
    "accuracies = []\n",
    "for d in dims:\n",
    "    classifier = train_hashing_svm(train, d)\n",
    "    predicted = classifier.predict(test_bow)\n",
    "    score = accuracy_score(test_classes, predicted)\n",
    "    accuracies.append(score)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Liczba cech')\n",
    "plt.ylabel('Trafność na zbiorze testowym')\n",
    "plt.plot(dims, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82f3f52a6fe2a10a300b5d45101b32b5",
     "grade": false,
     "grade_id": "cell-eab7c2a5f0251ff4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - Obserwując stworzony wykres - skomentuj. Jak dużo jakości klasyfikacji się traci (albo zyskuje?) korzystając z mniejszej liczby haszowanych cech? Często klasyfikatory bardzo dobrze działają nawet przy liczbie haszowanych cech dla których na pewno istnieją konflikty cech oryginalnych - jak myślisz dlaczego? (Pomyśl o interpretacji takich skonfliktowanych cech)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed30f2d487da41cf1a92ffb63195d621",
     "grade": true,
     "grade_id": "cell-2caea1821af5d8aa",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20139da166319b49eea5cc7e984fc08e",
     "grade": false,
     "grade_id": "cell-0d86672dbabbf54d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - W poprzednim zadaniu wczytałeś wynik grupowania Browna do pamięci. Wytrenuj klasyfikator na reprezentacji ,,Bag-of-clusters'' tj. w kolumnach zamiast słów/n-gramów będziesz miał grupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b13c0457af5dab17e12780eafb1c5ac4",
     "grade": true,
     "grade_id": "cell-55264f6fe514d007",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111010101011111, 11101110, 110100, 0, 1011100, 1111010110110, 11001100, 11111001110, 100110111, 11011110, 10010, 11010000, 1111111110, 111101110011111, 111000010110, 10001101, 1110101010110, 1000100], [11101110, 11010110, 110111010, 1110100, 10110111110, 11000, 1111011110010, 11010100, 1000010, 1000, 10110010111, 110110, 1101100111, 111100110111100, 1000100, 1111111100, 11001100, 110100, 1111110101110, 1111001111110, 1111111100, 10011110, 1011111110, 100110111, 0, 11001010, 110110110, 11110100010, 10110, 1110110, 10001110], [110100111, 0, 10110111110, 11000, 111101110111110, 10011110, 11000, 0, 1111110001010, 11110111000110, 1000100, 1110111, 0, 111100110100, 101110, 111100011110, 1010, 10100111111, 100110111, 10110010110, 1110110, 10111111, 11100110110, 10001101, 11101110, 11101110], [111001100001, 10010, 0, 11101010, 1000, 100011011, 11011100, 11111100110110, 1111110010010, 10110, 11111100110110, 1000100, 11010000, 10010, 1110100, 100000, 10110111110, 11000, 1101100110, 11111011111111, 1111110011001, 1111011110010, 1000100, 0, 11101110], [0, 11101110, 0, 1110111, 101110, 1101111110100, 100110111, 101101010, 0, 101110, 11111010, 1011100, 101111010, 110100, 1111110101110, 111111011101110, 1001110010, 111100011100, 1110110, 1111110100, 1000100, 0], [11101110, 1111110101110, 1111011100000, 1011101000, 111111010000, 11110111001000, 10001110, 10001110, 10001110, 0, 100011111110, 100, 1110111, 10110011011, 1111111100, 100111000, 11110111000110, 10001110, 0], [10100, 10011010101, 110110, 1111110101110, 1010111, 11110101101110, 10001011, 11101110, 111101111100100, 1111110010101, 1111111010110, 10010, 0, 11110101101110, 11110111000110, 1000100, 110100011111, 1110110, 111101110011, 11111010, 1011100, 111101111001111, 1010, 10110011011, 110110, 1111011100000, 11101011001011], [1001110111, 111100011100, 11000, 10110011011, 10010, 1110110, 101111110, 1111001101100, 10010, 1001110011, 10010, 1110101100110, 11110101101111, 111001, 1000, 10101010111, 1101111110110, 10010, 0, 1001100, 111010101110111, 1000100, 11101110, 11101010, 100100, 111101111100100, 1110010, 1111011111110, 11111110100, 1000100], [111101011101, 111100111001, 10010, 111110000110, 111100111010, 110110110, 1111001111110, 1010, 11101010100111, 10111111, 0, 11101110, 0, 0], [1000011, 11101110, 101010011110, 11110101101111, 11111110101110, 10001101, 110010110, 1010001101, 11111011111111, 10111110, 111101011101, 11010000, 11111110, 0, 111001101111, 1000, 10110110, 11110010010, 110100, 11110111001010, 11110111001110, 1001110110, 1110110, 1111101111110, 1111100, 1000100]]\n"
     ]
    }
   ],
   "source": [
    "brown_dict = { row['word']: row['cluster'] for _, row in brown_df.iterrows() }\n",
    "# ^damn slow\n",
    "\n",
    "def bag_of_clusters(tweets):\n",
    "    return [\n",
    "        [brown_dict.get(token, 0) for token in tweet.tokens]\n",
    "        for tweet in tweets\n",
    "    ]\n",
    "\n",
    "print(bag_of_clusters(training_set.tweets[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e47a053ebc12ac2fd97d9c11187da9b",
     "grade": false,
     "grade_id": "cell-493071698fc0205e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Podsumuj eksperymenty: poznałeś dwie możliwości ograniczenia liczby cech - zastąpienie słów ich grupami i haszowanie cech. Jakie są wady i zalety obydwu podejść?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b80ace505afba9b12fd5d3896a9046ef",
     "grade": true,
     "grade_id": "cell-4508400659f7243e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
